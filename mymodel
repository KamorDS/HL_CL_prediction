import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sbs
import numpy as np
import joblib


url = "https://raw.githubusercontent.com/MainakRepositor/Datasets/master/energy_efficiency_data.csv"
df = pd.read_csv(url)
df
df.describe(include='all')
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
Xc = scaler.fit_transform(df)


Xc
df.columns = ['X' + str(i+1) for i in range(len(df.columns))]
plt.figure(figsize = (8,5))
sbs.heatmap(df.corr(), cbar = False, annot = True, fmt=".1f")
n_rows=2
n_cols=4

# Create the subplots
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)
fig.set_size_inches(10, 5)
for i, column in enumerate(df.iloc[:, :-2].columns):
    sbs.histplot(df[column], ax=axes[i//n_cols, i % n_cols], kde=True)
plt.tight_layout()
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split


X = df.iloc[:, :8]
y = df.iloc[:, -2:]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



for col in X_train.columns:
    print(f"{col} : ", X_train[f'{col}'].unique())
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)
fig.set_size_inches(10, 5)
for i, column in enumerate(df.iloc[:,:-2].columns):
    sbs.regplot(x = df[column], y = df['X9'],ax=axes[i//n_cols,i%n_cols], scatter_kws={"color": "green"}, line_kws={"color": "red"})
plt.tight_layout()
fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols)
fig.set_size_inches(10, 5)
for i, column in enumerate(df.iloc[:,:-2].columns):
    sbs.regplot(x = df[column], y = df['X10'],ax=axes[i//n_cols,i%n_cols], scatter_kws={"color": "black" , 'cmap':'jet'}, line_kws={"color": "red"})
plt.tight_layout()
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error

def printPredictions(y_true,y_pred, count):
  print(f"Predictions: ")
  print(y_true.assign(
      Y1_pred = y_pred[:,0],
      Y2_pred = y_pred[:,1]
  ).head(count).to_markdown(index = False))

def showResults(y_true, y_pred, count = 5):
  print("R2 score: ",r2_score(y_true,y_pred))
  print("Mean squared error: ",mean_squared_error(y_true,y_pred))
  print("Mean absolute error: ",mean_absolute_error(y_true,y_pred))
  printPredictions(y_true,y_pred, count)
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,:-2], df.iloc[:,-2:], test_size = 0.2, random_state = 42)
print(X_train.shape,X_test.shape)
print(y_train.shape, y_test.shape)

linear = LinearRegression()
linear.fit(X_train,y_train)
showResults(y_test,linear.predict(X_test))
from sklearn.ensemble import RandomForestRegressor
rdf = RandomForestRegressor()
rdf.fit(X_train,y_train)
showResults(y_test,rdf.predict(X_test))

from sklearn.ensemble import ExtraTreesRegressor
extra_reg = ExtraTreesRegressor()
extra_reg.fit(X_train,y_train)
showResults(y_test,extra_reg.predict(X_test))
from sklearn.neighbors import KNeighborsRegressor
knn = KNeighborsRegressor()
knn.fit(X_train,y_train)
showResults(y_test,knn.predict(X_test))
joblib.dump(rdf, "rf_model.sav")
